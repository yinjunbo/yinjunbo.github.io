<!doctype html><!-- This site was created with Wowchemy. https://www.wowchemy.com --><!-- Last Published: January 15, 2024 --><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=generator content="Wowchemy 5.7.0 for Hugo"><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=preload as=style href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap"><link rel=stylesheet href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap" media=print onload='this.media="all"'><link rel=stylesheet href=/css/vendor-bundle.min.047268c6dd09ad74ba54a0ba71837064.css media=print onload='this.media="all"'><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/academicons@1.9.2/css/academicons.min.css integrity="sha512-KlJCpRsLf+KKu2VQa5vmRuClRFjxc5lXO03ixZt82HZUk41+1I0bD8KBSA0fY290ayMfWYI9udIqeOWSu1/uZg==" crossorigin=anonymous media=print onload='this.media="all"'><link rel=stylesheet href=/css/wowchemy.042e26407c9e383d96a1f26d6787c686.css><link rel=stylesheet href=/css/libs/chroma/github-light.min.css title=hl-light media=print onload='this.media="all"'><link rel=stylesheet href=/css/libs/chroma/dracula.min.css title=hl-dark media=print onload='this.media="all"' disabled><meta name=author content="Junbo Yin 阴俊博"><meta name=description content="A highly-customizable Hugo academic resume theme powered by Wowchemy website builder."><link rel=alternate hreflang=en-us href=https://yinjunbo.github.io/publication-type/1/><link rel=canonical href=https://yinjunbo.github.io/publication-type/1/><link rel=manifest href=/manifest.webmanifest><link rel=icon type=image/png href=/media/icon_hub176d598b0f976174f6ebf45074facb3_20991_32x32_fill_lanczos_center_3.png><link rel=apple-touch-icon type=image/png href=/media/icon_hub176d598b0f976174f6ebf45074facb3_20991_180x180_fill_lanczos_center_3.png><meta name=theme-color content="#1565c0"><meta property="twitter:card" content="summary"><meta property="twitter:site" content="@wowchemy"><meta property="twitter:creator" content="@wowchemy"><meta property="twitter:image" content="https://yinjunbo.github.io/media/icon_hub176d598b0f976174f6ebf45074facb3_20991_512x512_fill_lanczos_center_3.png"><meta property="og:site_name" content="Junbo Yin"><meta property="og:url" content="https://yinjunbo.github.io/publication-type/1/"><meta property="og:title" content="1 | Junbo Yin"><meta property="og:description" content="A highly-customizable Hugo academic resume theme powered by Wowchemy website builder."><meta property="og:image" content="https://yinjunbo.github.io/media/icon_hub176d598b0f976174f6ebf45074facb3_20991_512x512_fill_lanczos_center_3.png"><meta property="og:locale" content="en-us"><meta property="og:updated_time" content="2023-02-01T00:00:00+00:00"><link rel=alternate href=/publication-type/1/index.xml type=application/rss+xml title="Junbo Yin"><title>1 | Junbo Yin</title></head><body id=top data-spy=scroll data-offset=70 data-target=#TableOfContents class=page-wrapper><script src=/js/wowchemy-init.min.ec9d49ca50e4b80bdb08f0417a28ed84.js></script><aside class=search-modal id=search><div class=container><section class=search-header><div class="row no-gutters justify-content-between mb-3"><div class=col-6><h1>Search</h1></div><div class="col-6 col-search-close"><a class=js-search href=# aria-label=Close><i class="fas fa-times-circle text-muted" aria-hidden=true></i></a></div></div><div id=search-box><input name=q id=search-query placeholder=Search... autocapitalize=off autocomplete=off autocorrect=off spellcheck=false type=search class=form-control aria-label=Search...></div></section><section class=section-search-results><div id=search-hits></div></section></div></aside><div class="page-header header--fixed"><header><nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id=navbar-main><div class=container-xl><div class="d-none d-lg-inline-flex"><a class=navbar-brand href=/>Junbo Yin</a></div><button type=button class=navbar-toggler data-toggle=collapse data-target=#navbar-content aria-controls=navbar-content aria-expanded=false aria-label="Toggle navigation">
<span><i class="fas fa-bars"></i></span></button><div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none"><a class=navbar-brand href=/>Junbo Yin</a></div><div class="navbar-collapse main-menu-item collapse justify-content-start" id=navbar-content><ul class="navbar-nav d-md-inline-flex"><li class=nav-item><a class=nav-link href=/#about><span>Home</span></a></li><li class=nav-item><a class=nav-link href=/#news><span>News</span></a></li><li class=nav-item><a class=nav-link href=/#publications><span>Publications</span></a></li><li class=nav-item><a class=nav-link href=/#activities><span>Activities</span></a></li></ul></div><ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2"><li class="nav-item d-none d-lg-inline-flex"><a class=nav-link href="https://scholar.google.com/citations?user=OiEQrqUAAAAJ&amp;hl=zh-CN" target=_blank rel=noopener aria-label=google-scholar><i class="ai ai-google-scholar" aria-hidden=true></i></a></li><li class=nav-item><a class="nav-link js-search" href=# aria-label=Search><i class="fas fa-search" aria-hidden=true></i></a></li><li class="nav-item dropdown theme-dropdown"><a href=# class=nav-link data-toggle=dropdown aria-haspopup=true aria-label="Display preferences"><i class="fas fa-moon" aria-hidden=true></i></a><div class=dropdown-menu><a href=# class="dropdown-item js-set-theme-light"><span>Light</span>
</a><a href=# class="dropdown-item js-set-theme-dark"><span>Dark</span>
</a><a href=# class="dropdown-item js-set-theme-auto"><span>Automatic</span></a></div></li></ul></div></nav></header></div><div class=page-body><div class="universal-wrapper pt-3"><h1>1</h1></div><div class=universal-wrapper><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/publication/aaai23lwsis/>LWSIS: LiDAR-Guided Weakly Supervised Instance Segmentation for Autonomous Driving</a></div><a href=/publication/aaai23lwsis/ class=summary-link><div class=article-style>We present a novel learning paradigm, LWSIS, that inherits the fruits of off-the-shelf 3D point cloud to guide the training of 2D instance segmentation models to save mask-level annotations. We advocate a new dataset nuInsSeg based on nuScenes to extend existing 3D LiDAR annotations with 2D image segmentation annotations.</div></a><div class="stream-meta article-metadata"><div><span>Xiang Li</span><i class="author-notes fas fa-info-circle" data-toggle=tooltip title="Equal contribution"></i>, <span>Junbo Yin</span><i class="author-notes fas fa-info-circle" data-toggle=tooltip title="Equal contribution"></i>, <span>Botian Shi</span>, <span>Yikang Li</span>, <span>Ruigang Yang</span>, <span>Jianbing Shen</span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://ojs.aaai.org/index.php/AAAI/article/view/25228/25000 target=_blank rel=noopener>PDF
</a><a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/aaai23lwsis/cite.bib>Cite
</a><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.%20com/Serenos/LWSIS target=_blank rel=noopener>Code
</a><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/Serenos/nuInsSeg target=_blank rel=noopener>Dataset</a></div></div><div class=ml-3><a href=/publication/aaai23lwsis/><img src=/publication/aaai23lwsis/featured_hu338c1f3e801374ac0a802ac8924065fb_605234_150x0_resize_q75_h2_lanczos.webp height=77 width=150 alt="LWSIS: LiDAR-Guided Weakly Supervised Instance Segmentation for Autonomous Driving" loading=lazy></a></div></div><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/publication/aaai23ssda/>SSDA3D: Semi-supervised Domain Adaptation for 3D Object Detection from Point Cloud</a></div><a href=/publication/aaai23ssda/ class=summary-link><div class=article-style>We prsent SSDA3D in this work, which is the first effort for semi-supervised domain adaptation in the context of 3D object detection. SSDA3D is achieved by a novel framework that jointly addresses inter-domain adaptation and intra-domain generalization.</div></a><div class="stream-meta article-metadata"><div><span>Yan Wang</span><i class="author-notes fas fa-info-circle" data-toggle=tooltip title="Equal contribution"></i>, <span>Junbo Yin</span><i class="author-notes fas fa-info-circle" data-toggle=tooltip title="Equal contribution"></i>, <span>Wei Li</span>, <span>Pascal Frossard</span>, <span>Ruigang Yang</span>, <span>Jianbing Shen</span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://ojs.aaai.org/index.php/AAAI/article/view/25370/25142 target=_blank rel=noopener>PDF
</a><a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/aaai23ssda/cite.bib>Cite
</a><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.%20com/yinjunbo/SSDA3D target=_blank rel=noopener>Code</a></div></div><div class=ml-3><a href=/publication/aaai23ssda/><img src=/publication/aaai23ssda/featured_hu03e363b4f2548340ac004b76b3c000c4_1283827_150x0_resize_q75_h2_lanczos.webp height=86 width=150 alt="SSDA3D: Semi-supervised Domain Adaptation for 3D Object Detection from Point Cloud" loading=lazy></a></div></div><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/publication/eccv22self/>ProposalContrast: Unsupervised Pre-training for LiDAR-based 3D Object Detection</a></div><a href=/publication/eccv22self/ class=summary-link><div class=article-style>We propose a proposal-level point cloud SSL framework, named ProposalContrast, that conducts proposal-wise contrastive pre-training for detection-aligned representation learning. We comprehensively demonstrate the generalizability of our model across diverse 3D detector architectures and datasets.</div></a><div class="stream-meta article-metadata"><div><span>Junbo Yin</span>, <span>Dingfu Zhou</span>, <span>Liangjun Zhang</span>, <span>Jin Fang</span>, <span>Cheng-Zhong Xu</span>, <span>Jianbing Shen</span>, <span>Wenguan Wang</span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136990017.pdf target=_blank rel=noopener>PDF
</a><a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/eccv22self/cite.bib>Cite
</a><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/yinjunbo/ProposalContrast target=_blank rel=noopener>Code</a></div></div><div class=ml-3><a href=/publication/eccv22self/><img src=/publication/eccv22self/featured_huf2ef780a5664fc61c657f0b2a6dcaee2_2282284_150x0_resize_q75_h2_lanczos.webp height=91 width=150 alt="ProposalContrast: Unsupervised Pre-training for LiDAR-based 3D Object Detection" loading=lazy></a></div></div><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/publication/eccv22semi/>Semi-supervised 3D Object Detection wit Proficient Teachers</a></div><a href=/publication/eccv22semi/ class=summary-link><div class=article-style>We propose ProficientTeachers for LiDAR-based 3D object detection, which is achieved by promoting the plain teacher model to proficient teachers inspired by ensemble learning. Our framework not only performs better results, but also removes the necessity of confidencebased thresholds for filtering pseudo labels.</div></a><div class="stream-meta article-metadata"><div><span>Junbo Yin</span>, <span>Jin Fang</span>, <span>Dingfu Zhou</span>, <span>Liangjun Zhang</span>, <span>Cheng-Zhong Xu</span>, <span>Jianbing Shen</span>, <span>Wenguan Wang</span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136980710.pdf target=_blank rel=noopener>PDF
</a><a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/eccv22semi/cite.bib>Cite</a></div></div><div class=ml-3><a href=/publication/eccv22semi/><img src=/publication/eccv22semi/featured_hu5c1355f6f10dcb05f8b806821474919a_1262879_150x0_resize_q75_h2_lanczos.webp height=74 width=150 alt="Semi-supervised 3D Object Detection wit Proficient Teachers" loading=lazy></a></div></div><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/publication/cvpr20mot/>A Unified Object Motion and Affinity Model for Online Multi-Object Tracking</a></div><a href=/publication/cvpr20mot/ class=summary-link><div class=article-style>We integrates singl object tracking and metric learning into a unified triplet network via multi-task learning. A task-specific attention module is also presented to address th specific nature of each task. Experimental results show that it achieves promising performance on several MOT benchmarks.</div></a><div class="stream-meta article-metadata"><div><span>Junbo Yin</span>, <span>Wenguan Wang</span>, <span>Qinghao Meng</span>, <span>Ruigang Yang</span>, <span>Jianbing Shen</span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://openaccess.thecvf.com/content_CVPR_2020/papers/Yin_A_Unified_Object_Motion_and_Affinity_Model_for_Online_Multi-Object_CVPR_2020_paper.pdf target=_blank rel=noopener>PDF
</a><a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/cvpr20mot/cite.bib>Cite
</a><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/yinjunbo/UMA-MOT target=_blank rel=noopener>Code</a></div></div><div class=ml-3><a href=/publication/cvpr20mot/><img src=/publication/cvpr20mot/featured_hu4b8f58dea55ba086a0c00bb290433673_405889_150x0_resize_q75_h2_lanczos.webp height=51 width=150 alt="A Unified Object Motion and Affinity Model for Online Multi-Object Tracking" loading=lazy></a></div></div><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/publication/cvpr20vid/>LiDAR-based Online 3D Video Object Detection with Graph-based Message Passing and Spatiotemporal Transformer Attention</a></div><a href=/publication/cvpr20vid/ class=summary-link><div class=article-style>We propose a new LiDAR-based 3D video object detector that leverages the previous long-term information to improve the 3D detection performance. Extensive evaluations demonstrate that our 3D video object detector achieves better performance against the single-frame detectors.</div></a><div class="stream-meta article-metadata"><div><span>Junbo Yin</span>, <span>Jianbing Shen</span>, <span>Chenye Guan</span>, <span>Dingfu Zhou</span>, <span>Ruigang Yan</span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://openaccess.thecvf.com/content_CVPR_2020/papers/Yin_LiDAR-Based_Online_3D_Video_Object_Detection_With_Graph-Based_Message_Passing_CVPR_2020_paper.pdf target=_blank rel=noopener>PDF
</a><a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/cvpr20vid/cite.bib>Cite</a></div></div><div class=ml-3><a href=/publication/cvpr20vid/><img src=/publication/cvpr20vid/featured_hu94ea230965639de5401c8cb30fc8acd6_876587_150x0_resize_q75_h2_lanczos.webp height=107 width=150 alt="LiDAR-based Online 3D Video Object Detection with Graph-based Message Passing and Spatiotemporal Transformer Attention" loading=lazy></a></div></div><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/publication-template/conference-paper/>An example conference paper</a></div><a href=/publication-template/conference-paper/ class=summary-link><div class=article-style>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.</div></a><div class="stream-meta article-metadata"><div class=article-metadata><div><span class=author-highlighted>Junbo Yin 阴俊博</span><i class="author-notes fas fa-info-circle" data-toggle=tooltip title="Equal contribution"></i>, <span>Robert Ford</span><i class="author-notes fas fa-info-circle" data-toggle=tooltip title="Equal contribution"></i></div><span class=article-date>Jul 1, 2013</span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=/publication-template/conference-paper/conference-paper.pdf target=_blank rel=noopener>PDF
</a><a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication-template/conference-paper/cite.bib>Cite
</a><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/wowchemy/wowchemy-hugo-themes target=_blank rel=noopener>Code
</a><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/wowchemy/wowchemy-hugo-themes target=_blank rel=noopener>Dataset
</a><a class="btn btn-outline-primary btn-page-header btn-sm" href=/project/example/>Project
</a><a class="btn btn-outline-primary btn-page-header btn-sm" href=/slides/example/ target=_blank>Slides
</a><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://youtube.com target=_blank rel=noopener>Video
</a><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/wowchemy/wowchemy-hugo-themes target=_blank rel=noopener>Source Document</a></div></div><div class=ml-3><a href=/publication-template/conference-paper/><img src=/publication-template/conference-paper/featured_hu3d03a01dcc18bc5be0e67db3d8d209a6_312700_150x0_resize_q75_h2_lanczos.webp height=100 width=150 alt="An example conference paper" loading=lazy></a></div></div></div></div><div class=page-footer><div class=container><footer class=site-footer><p class=powered-by>Published with <a href="https://wowchemy.com/?utm_campaign=poweredby" target=_blank rel=noopener>Wowchemy</a> — the free, <a href=https://github.com/wowchemy/wowchemy-hugo-themes target=_blank rel=noopener>open source</a> website builder that empowers creators.</p></footer></div></div><script src=/js/vendor-bundle.min.938a3a7554cd9f6602290411f64d2617.js></script><script id=search-hit-fuse-template type=text/x-template>
    <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
    </div>
  </script><script src=https://cdn.jsdelivr.net/gh/krisk/Fuse@v3.2.1/dist/fuse.min.js integrity="sha512-o38bmzBGX+hD3JHWUFCDA09btWaqrNmoJ3RXLlrysA7PP01Kgs4UlE4MhelE1v5dJR3+cxlR4qQlotsW7jKsnw==" crossorigin=anonymous></script><script src=https://cdn.jsdelivr.net/gh/julmot/mark.js@8.11.1/dist/jquery.mark.min.js integrity="sha512-mhbv5DqBMgrWL+32MmsDOt/OAvqr/cHimk6B8y/bx/xS88MVkYGPiVv2ixKVrkywF2qHplNRUvFsAHUdxZ3Krg==" crossorigin=anonymous></script><script id=page-data type=application/json>{"use_headroom":true}</script><script src=/js/wowchemy-headroom.db4755770454eb63685f8de785c0a172.js type=module></script><script src=/en/js/wowchemy.min.85070d5fe00d43eaedff44310b81dc2c.js></script><div id=modal class="modal fade" role=dialog><div class=modal-dialog><div class=modal-content><div class=modal-header><h5 class=modal-title>Cite</h5><button type=button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body><pre><code></code></pre></div><div class=modal-footer><a class="btn btn-outline-primary my-1 js-copy-cite" href=# target=_blank><i class="fas fa-copy"></i> Copy
</a><a class="btn btn-outline-primary my-1 js-download-cite" href=# target=_blank><i class="fas fa-download"></i> Download</a><div id=modal-error></div></div></div></div></div><script src=/js/wowchemy-publication.68f8d7090562ca65fc6d3cb3f8f2d2cb.js type=module></script></body></html>